{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f9d55",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    body {\n",
       "        font-size: 18px;\n",
       "        font-family: Georgia, serif;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML \n",
    "<style>\n",
    "    body {\n",
    "        font-size: 18px;\n",
    "        font-family: Georgia, serif;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549af83b",
   "metadata": {},
   "source": [
    "Let's explain step-by-step how the program is able to obtain the different diagrams for the case where only gluons are considered. Describing what the different functions in the file `gluon_functions.py` does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a270fc09",
   "metadata": {},
   "source": [
    "Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "add86da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy.special import binom, factorial\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d8bef4",
   "metadata": {},
   "source": [
    "The theory that is being considered, meaning the type of particles involved and the type of interactions is described in the canonical diagrams. This diagrams are defined in a separate python file that we need to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1505115",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Import the canoncial diagrams\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcan_diagrams\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgluon_diagrams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "#Import the canoncial diagrams\n",
    "from functions.can_diagrams.gluon_diagrams import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f555927b",
   "metadata": {},
   "source": [
    "Once the diagrams are defined we need a way to display the diagrams. \n",
    "During the operation with diagrams there will be \"artifacts\" (0 values between other non-zero values) in the different arrays, and we chose to solve these problem at the end when representing the diagrams, since before that many different diagrams are grouped and the modification of it's dimensions can cause many problems.\n",
    "\n",
    "- trim_zeros_2D: to remove the 0 arrays from the `points` array.\n",
    "- trim_zeros_3D: to remove the 0 arrays from the `paths` array.\n",
    "- find_equal_subrrays: to find the loops in the diagrams that will be represented with a circle.\n",
    "- prune_points_and_reindex: the first 2 functions can only be used when the 0's are at the start or at the end. But the 0's are located in the middle of other non_zero values, the modification of the `points` array will supone changes to the `paths` array.\n",
    "\n",
    "    Example: \n",
    "    - Starting points: `[[1, 1], [0, 0], [1, 2], [2, 3]]`\n",
    "    - Starting paths: `[[[1, 3], [3, 4]], [[0, 0], [0, 0]]]`\n",
    "\n",
    "    We want to remove the `[0, 0]` from the points path, but if we do so directly, the conections in the paths will be wrong. When removing the points, we need to shift all the number in the paths greater than the position of the removed point down.\n",
    "    - Final points: `[[1, 1], [1, 2], [2, 3]]`\n",
    "    - Starting paths: `[[[1, 2], [2, 3]], [[0, 0], [0, 0]]]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104312bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Chatgpt\n",
    "def trim_zeros_2D(array: np.ndarray, axis: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Remove any rows (axis=1) or columns (axis=0) that are entirely zero,\n",
    "    even if they appear between non-zero rows/columns.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array : np.ndarray\n",
    "        2D input array.\n",
    "    axis : int, optional\n",
    "        If 1 (default), drop zero-rows; if 0, drop zero-columns.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The trimmed array.\n",
    "    \"\"\"\n",
    "    # mask[i] is True iff the i-th row/column has at least one non-zero\n",
    "    mask = array.any(axis=axis)\n",
    "    \n",
    "    if axis:\n",
    "        # drop rows where mask is False\n",
    "        return array[mask, :]\n",
    "    else:\n",
    "        # drop columns where mask is False\n",
    "        return array[:, mask]\n",
    "    \n",
    "#From chatgpt \n",
    "def trim_zeros_3D(array, axis=None):\n",
    "    if axis is None:\n",
    "        # Trim along all axes\n",
    "        mask = ~(array == 0).all(axis=(1, 2))\n",
    "        trimmed_array = array[mask]\n",
    "\n",
    "        mask = ~(trimmed_array == 0).all(axis=(0, 2))\n",
    "        trimmed_array = trimmed_array[:, mask]\n",
    "\n",
    "        mask = ~(trimmed_array == 0).all(axis=(0, 1))\n",
    "        trimmed_array = trimmed_array[:, :, mask]\n",
    "    elif axis == 0:\n",
    "        # Trim along axis 0\n",
    "        mask = ~(array == 0).all(axis=(1, 2))\n",
    "        trimmed_array = array[mask]\n",
    "    elif axis == 1:\n",
    "        # Trim along axis 1\n",
    "        mask = ~(array == 0).all(axis=(0, 2))\n",
    "        trimmed_array = array[:, mask]\n",
    "    elif axis == 2:\n",
    "        # Trim along axis 2\n",
    "        mask = ~(array == 0).all(axis=(0, 1))\n",
    "        trimmed_array = array[:, :, mask]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid axis. Axis must be 0, 1, 2, or None.\")\n",
    "    \n",
    "    return trimmed_array\n",
    "\n",
    "#From Chatgpt\n",
    "def find_equal_subarrays(array):\n",
    "    \"\"\"\"\n",
    "    Find the positions of duplicate subarrays in a 2D array.\n",
    "    Args:\n",
    "        array (np.array): 2D array to search for duplicates\n",
    "    Returns:\n",
    "        duplicate_positions (list): list of positions of duplicate\n",
    "    \"\"\"\n",
    "    sorted_subarrays = [np.sort(subarray) for subarray in array]\n",
    "    unique_subarrays, indices, counts = np.unique(sorted_subarrays, axis=0, return_index=True, return_counts=True)\n",
    "    duplicate_positions = [np.where((sorted_subarrays == unique_subarrays[i]).all(axis=1))[0] for i in range(len(unique_subarrays)) if counts[i] > 1]\n",
    "    return duplicate_positions\n",
    "\n",
    "#From Chatgpt\n",
    "def prune_points_and_reindex(points: np.ndarray,\n",
    "                              paths: np.ndarray\n",
    "                             ) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Remove all [0,0] rows from `points`, then rebuild `paths` so that:\n",
    "      - any path entry pointing to a removed point becomes 0,\n",
    "      - all other entries are remapped down to a compact 1-based range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    points : np.ndarray, shape (N,2)\n",
    "        Your (x,y) coordinates, with placeholder rows exactly equal to [0,0].\n",
    "    paths : np.ndarray, shape (T,P,2), dtype=int\n",
    "        Your 1-based index pairs, with [0,0] as placeholders.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_points : np.ndarray, shape (M,2)\n",
    "        The pruned points (no [0,0] rows).\n",
    "    new_paths  : np.ndarray, shape (T,P,2)\n",
    "        The updated paths, still 1-based with [0,0] placeholders.\n",
    "    \"\"\"\n",
    "    # 1) Mask of rows to keep\n",
    "    keep = ~(np.all(points == 0, axis=1))\n",
    "    new_points = points[keep]\n",
    "    \n",
    "    # 2) Build old→new 1-based map\n",
    "    #    new_idx[i] = new 1-based index of old row i, or 0 if dropped\n",
    "    new_idx = np.zeros(points.shape[0], dtype=int)\n",
    "    new_idx[keep] = np.arange(1, keep.sum()+1)\n",
    "    \n",
    "    # 3) Apply to paths\n",
    "    #    For each entry u in paths: if u>0, replace with new_idx[u-1], else keep 0\n",
    "    T, P, _ = paths.shape\n",
    "    flat = paths.reshape(-1,2)\n",
    "    # map both columns at once:\n",
    "    mapped = np.zeros_like(flat)\n",
    "    for col in (0,1):\n",
    "        # grab the column, subtract 1 for 0-based indexing into new_idx\n",
    "        o = flat[:,col]\n",
    "        # for non-zero entries, look up new index; zeros stay zero\n",
    "        mapped[:,col] = np.where(o>0, new_idx[o-1], 0)\n",
    "    new_paths = mapped.reshape(T, P, 2)\n",
    "    \n",
    "    return new_points, new_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent_diagram (points, all_paths, index = False, directory = \"\", colors = [\"tab:blue\", \"tab:red\", \"black\"], line = [\"solid\", \"solid\", \"photon\"], count = 0):\n",
    "    \"\"\"\n",
    "    Represent a diagram with points and paths.\n",
    "    Args:\n",
    "        points (np.array): array of points of dimension (n, 2)\n",
    "        all_paths (list): list of paths to represent\n",
    "        index (bool): whether to show the index of each point\n",
    "        directory (str): directory to save the diagram\n",
    "        colors (list): list of colors for each path\n",
    "        line (list): list of line styles for each path\n",
    "    \"\"\"\n",
    "    if (np.all(all_paths == 0)):\n",
    "        return \n",
    "    \n",
    "    points, all_paths = prune_points_and_reindex(points, all_paths)\n",
    "\n",
    "    points = trim_zeros_2D(points)\n",
    "    all_paths = trim_zeros_3D(all_paths, axis=1)\n",
    "    \n",
    "    fig=plt.figure(figsize=(5,3)) \n",
    "    ax=fig.add_subplot(111)\n",
    "    ax.axis('off')\n",
    "    j = 0\n",
    "\n",
    "    # Note the that here the paths are more similar to the 1 particle case, meaning that is a 2D array\n",
    "    for paths in all_paths:\n",
    "        loops = find_equal_subarrays(paths)\n",
    "        # Following the point made previously len(paths) indicate the number of connections instead of number of types of particles.\n",
    "        for i in range(len(paths)):\n",
    "            # In the case that the type of particle is a photon a spetial type of line is used to represent it.\n",
    "            if (line[j] == \"photon\"):\n",
    "                with mpl.rc_context({'path.sketch': (3, 15, 1)}):\n",
    "                    if np.isin(i, loops):\n",
    "                        middle_point = (points[paths[i, 0]-1] + points[paths[i, 1]-1]) / 2\n",
    "                        circle = plt.Circle((middle_point[0], middle_point[1]), np.linalg.norm(points[paths[i, 0]-1]-middle_point), color=colors[j], fill=False)\n",
    "                        ax.add_patch(circle)\n",
    "                    elif paths[i, 0] == paths[i, 1] and paths[i ,0] != 0:\n",
    "                        ax.scatter(points[paths[i, 0]-1, 0], points[paths[i, 0]-1, 1], color = colors[j])\n",
    "                    else:\n",
    "                        ax.plot([points[paths[i, 0]-1, 0], points[paths[i, 1]-1, 0]], [points[paths[i, 0]-1, 1], points[paths[i, 1]-1, 1]], color=colors[j])\n",
    "            else:\n",
    "                if np.isin(i, loops):\n",
    "                    middle_point = (points[paths[i, 0]-1] + points[paths[i, 1]-1]) / 2\n",
    "                    circle = plt.Circle((middle_point[0], middle_point[1]), np.linalg.norm(points[paths[i, 0]-1]-middle_point), color=colors[j], fill=False, linestyle=line[j])\n",
    "                    ax.add_patch(circle)\n",
    "                elif paths[i, 0] == paths[i, 1] and paths[i ,0] != 0:\n",
    "                    ax.scatter(points[paths[i, 0]-1, 0], points[paths[i, 0]-1, 1], color = colors[j], s = 50, zorder = 10)\n",
    "                else:\n",
    "                    ax.plot([points[paths[i, 0]-1, 0], points[paths[i, 1]-1, 0]], [points[paths[i, 0]-1, 1], points[paths[i, 1]-1, 1]], color=colors[j], linestyle=line[j])\n",
    "        j+=1\n",
    "    ax.axis('equal')\n",
    "    if index:\n",
    "        for i in range(len(points)):\n",
    "            ax.text(points[i, 0], points[i, 1], str(i+1), fontsize=12, color=\"black\", ha=\"right\", va=\"top\")\n",
    "    if count !=0:\n",
    "        ax.text(0.5, 0.5, f\"N = {count}\", fontsize=12, color=\"black\", ha=\"center\", va=\"center\")\n",
    "    if directory != \"\":\n",
    "        plt.savefig(directory, bbox_inches='tight')\n",
    "        plt.close() #Added to not show in the notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adaf611",
   "metadata": {},
   "source": [
    "Depending on the type of interaction that we are interested in studiying, we are interested in knowing the number and type of the particles at the start of the process and at the end. Thus we need a function that returns from the `path` array that only appear once (`unique_values`). \n",
    "\n",
    "Using that function `in_out_paths` returns the points where particles of different type enter/exit.\n",
    "\n",
    "At the end of the calculation we will move these points to the edges of the diagram, but during calculations, these points most likely are in the middle of the diagram, thus using the paths to identify them is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Github copilot\n",
    "def unique_values(array):\n",
    "    unique, counts = np.unique(array, return_counts=True)\n",
    "    unique_values = unique[counts == 1]\n",
    "    return unique_values\n",
    "\n",
    "def in_out_paths (paths):\n",
    "    max_len = max([len(path) for path in paths])\n",
    "    #len(paths) is the number of type of particles\n",
    "    in_out_paths = np.zeros((len(paths), 2, max_len), dtype=int)\n",
    "    unique_vals = unique_values(paths.flatten())\n",
    "    for i in range(len(paths)):\n",
    "        inp = 0\n",
    "        out = 0\n",
    "        for j in range(max_len):\n",
    "            if paths[i, j, 0] in unique_vals:\n",
    "                in_out_paths[i, 1, out] = paths[i, j, 0]\n",
    "                out += 1\n",
    "            if paths[i, j, 1] in unique_vals:\n",
    "                in_out_paths[i, 0, inp] = paths[i, j, 1]\n",
    "                inp += 1\n",
    "    in_out_paths = trim_zeros_3D(in_out_paths, axis=2)\n",
    "    return in_out_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7275d58c",
   "metadata": {},
   "source": [
    "The product of diagrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b3ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_connected( max_connections, n_connections, n_1, n_2):\n",
    "    \"\"\"\n",
    "    Generate all possible combinations of connections between two diagrams.\n",
    "    Args:\n",
    "        max_connections (int): maximum number of connections between the two diagrams for each type of particle\n",
    "        n_connections (int): number of connections between the two diagrams taking into account the number of types of particles\n",
    "        n_1 (int): number of input for each type of particle\n",
    "        n_2 (int): number of output for each type of particle\n",
    "    Returns:\n",
    "        combinations (np.array): array of all possible combinations of connections between the two diagrams\n",
    "        of dimension (n_connections, max_connections, 2)\n",
    "    \"\"\"\n",
    "    combinations = np.zeros((n_connections, max_connections, 2), dtype=int)\n",
    "    n = 0 \n",
    "    while n < n_connections:\n",
    "        for j in range (n_1):\n",
    "            for k in range(n_2):\n",
    "                combinations[n, 0] = np.array([j+1, k+1])\n",
    "                n += 1\n",
    "                if n == n_connections:\n",
    "                    break\n",
    "            if n == n_connections:\n",
    "                break\n",
    "            \n",
    "    n = n_1*n_2\n",
    "    if max_connections >1:\n",
    "        while n < n_connections:\n",
    "            diff = False\n",
    "            i = 1\n",
    "            while i < max_connections:  \n",
    "                for j in range (n_1):\n",
    "                    for k in range(n_2):\n",
    "                        for l in range(i):\n",
    "                            if (j+1) != combinations[n, l, 0] and (k+1) != combinations[n, l, 1]:\n",
    "                                diff = True\n",
    "                            else:\n",
    "                                diff = False\n",
    "                        if diff:\n",
    "                            combinations[n, i] = np.array([j+1, k+1])\n",
    "                            n +=1   \n",
    "                        if n == n_connections:\n",
    "                            return combinations      \n",
    "                i += 1\n",
    "    else:\n",
    "        return combinations\n",
    "\n",
    "def connection (points1, paths1, points2, paths2, offset = 0, in_out_limit = [0, 0]):\n",
    "    in_out_paths1 = in_out_paths(paths1)\n",
    "    in_out_paths2 = in_out_paths(paths2)\n",
    "\n",
    "    n_types = len(in_out_paths1)\n",
    "\n",
    "    #Create the new points array\n",
    "    points = np.zeros((len(points1) + len(points2), 2))\n",
    "    points[:len(points1)] = points1\n",
    "    points[len(points1):] = points2 + np.array([np.max(points1)+1, offset])\n",
    "\n",
    "    #Displace the paths of the second diagram to rename the points\n",
    "    for i in range(n_types):\n",
    "        for j in range(len(in_out_paths2[0])):\n",
    "            for k in range(len(in_out_paths2[0, 0])):\n",
    "                if in_out_paths2[i, j, k] != 0:\n",
    "                    in_out_paths2[i, j, k] += len(points1)\n",
    "\n",
    "    #n1 and n2 indicate the number of input for each type of particle and output for each type of particle\n",
    "    n1 = np.zeros(n_types, dtype=int)\n",
    "    n2 = np.zeros(n_types, dtype=int)\n",
    "    for i in range(n_types):\n",
    "        n1[i] = len(np.trim_zeros(in_out_paths1[i, 0]))\n",
    "        n2[i] = len(np.trim_zeros(in_out_paths2[i, 1]))\n",
    "\n",
    "    #max_connections indicates the maximum number of connections between the two diagrams for each type of particle\n",
    "    max_connections = np.zeros(n_types, dtype=int)\n",
    "    for i in range(n_types):\n",
    "        max_connections[i] = min(n1[i], n2[i])\n",
    "\n",
    "    #n_connections indicates the number of connections between the two diagrams taking into account the number of types of particles\n",
    "    n_connections = np.zeros(n_types, dtype=int)\n",
    "    for j in range(n_types):\n",
    "        for i in range(int(max_connections[j])):\n",
    "            n_connections[j] += int(binom(n1[j], i+1)*binom(n2[j], i+1) * factorial(i+1))\n",
    "    \n",
    "    #n_connec indicates the total number of connections between the two diagrams\n",
    "    n_connec = 0\n",
    "    for subset in range(1, 1 << n_types):\n",
    "        product = 1\n",
    "        for i in range(n_types):\n",
    "            if subset & (1 << i):\n",
    "                product *= n_connections[i]\n",
    "        n_connec += product\n",
    "\n",
    "    #Use a dummy array to store all possible combinations of connections for each type of particle between the two diagrams\n",
    "    dummy_combinations = np.zeros((sum(n_connections), n_types,  max(max_connections), 2), dtype=int)\n",
    "    n = 0\n",
    "    for i in range(n_types):\n",
    "        dummy_var = how_connected(max_connections[i], n_connections[i], n1[i], n2[i])\n",
    "        for j in range(n_connections[i]):\n",
    "            for k in range(max_connections[i]):\n",
    "                if(dummy_var[j, k, 0] != 0 and dummy_var[j, k, 1] != 0):\n",
    "                    dummy_combinations[n, i, k] = dummy_var[j, k]\n",
    "                else:\n",
    "                    break\n",
    "            n+=1\n",
    "\n",
    "    #From the dummy array, create the array combinations that will store all possible combinations of connections between the two diagrams\n",
    "    #taking into account mixing different types of particles\n",
    "    combinations = np.zeros((n_connec, n_types, max(max_connections), 2), dtype=int)\n",
    "\n",
    "    #The first step is to store a copy of the dummy array in the combinations array, without considering the mixing of different \n",
    "    #types of particles since there will be diagrams without mixed particles.\n",
    "    n = 0\n",
    "    for i in range(n_types):\n",
    "        if (n_connections[i] == 0):\n",
    "            continue\n",
    "        for j in range(np.sum(n_connections[:i]), n_connections[i]+np.sum(n_connections[:i])):\n",
    "            for k in range(max_connections[i]):\n",
    "                if(dummy_combinations[j, i, k, 0] != 0 and dummy_combinations[j, i, k, 1] != 0):\n",
    "                    combinations[n, i, k] = dummy_combinations[j, i, k]\n",
    "                else:\n",
    "                    break\n",
    "            n+=1        \n",
    "\n",
    "    #The second step is to store the combinations of connections between the two diagrams taking into account the mixing of \n",
    "    #different types of particles. The process could be though as filling a tringular matrix with the combinations of connections\n",
    "    #between the two diagrams. The first row of the matrix corresponds to the one type case, the second row combining 2 elements of \n",
    "    #the first row, this means combining 2 types of particles, and so on.\n",
    "\n",
    "    #The variable n_start indicates the position in the combinations array where the combinations of connections between \n",
    "    #the two diagrams taking into account the mixing of different types of particles start.\n",
    "    n_start = n\n",
    "\n",
    "    n_prime = 0\n",
    "    for i in range(n_types-1):\n",
    "        leng = 0\n",
    "        for l in range(i+1, n_types):   \n",
    "            leng += n_connections[i]*n_connections[l]\n",
    "        for n in range(n_start, leng+n_start):\n",
    "            combinations[n, i] = dummy_combinations[n_prime, i]\n",
    "            for j in range(i+1, n_types):\n",
    "                combinations[n, j] = dummy_combinations[n-n_start+n_connections[i], j]\n",
    "        n_prime += 1    \n",
    "    #Create the paths array that will store the connections between the two diagrams.\n",
    "    paths = np.zeros((n_connec, n_types, len(paths1[0]) + len(paths2[0]) + max(max_connections), 2), dtype=int)\n",
    "    paths[:n_connec,:n_types,:len(paths1[0])] = paths1\n",
    "    for i in range(n_connec):\n",
    "        for j in range(n_types):\n",
    "            for k in range(max_connections[j]):\n",
    "                if (combinations[i,j, k, 0] != 0 and combinations[i,j, k, 1] != 0):\n",
    "                    paths[i,j, len(paths1[0])+k] = np.array([in_out_paths1[j,0, combinations[i, j, k, 0]-1], in_out_paths2[j,1, combinations[i, j, k, 1]-1]])\n",
    "            if (np.count_nonzero(paths2[j]) != 0):\n",
    "                for k in range(len(paths2[j])):\n",
    "                    if (paths2[j, k, 0] != 0 and paths2[j, k, 1] != 0):\n",
    "                        paths[i,j, len(paths1[0])+max(max_connections)+k] = paths2[j, k] + np.array([len(points1), len(points1)])\n",
    "\n",
    "    return points, paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648e3d4",
   "metadata": {},
   "source": [
    "Afer the products we simplify by removing the points that are not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5422e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrement_number_in_array(array, number):\n",
    "    array[array == number] -= 1\n",
    "    return array\n",
    "\n",
    "def simplify_diagram_it (points, paths):\n",
    "    \"\"\"\n",
    "    Function that will be iterated to simplify the diagram by removing the points and paths that are not needed.\n",
    "    \"\"\"\n",
    "    pos = np.zeros((2, 3), dtype=int)\n",
    "    for i in range(1, np.max(paths)+1):\n",
    "        count = 0\n",
    "        for j in range(len(paths)):\n",
    "            for k in range(len(paths[j])):\n",
    "                for l in range(2):\n",
    "                    if paths[j, k, l] == i:\n",
    "                        count += 1\n",
    "                        if count == 1:\n",
    "                            pos[0] = np.array([j, k, l])\n",
    "                        elif count == 2:\n",
    "                            pos[1] = np.array([j, k, l])\n",
    "                        else:\n",
    "                            break\n",
    "        if count == 2 and pos[0, 0] == pos[1, 0]:\n",
    "            j = pos[0, 0] # type of particle\n",
    "            points = np.delete(points, i-1, axis=0)\n",
    "            if pos[0, 2] == 0:\n",
    "                if pos[1, 2] == 0:\n",
    "                    prov = np.array([paths[j, pos[0, 1], 1], paths[j, pos[1, 1], 1]])\n",
    "                elif pos[1, 2] == 1:\n",
    "                    prov = np.array([paths[j, pos[0, 1], 1], paths[j, pos[1, 1], 0]])  \n",
    "            elif pos[0, 2] == 1:\n",
    "                if pos[1, 2] == 0:\n",
    "                    prov = np.array([paths[j, pos[0, 1], 0], paths[j, pos[1, 1], 1]])                  \n",
    "                elif pos[1, 1] == 1:\n",
    "                    prov = np.array([paths[j, pos[0, 1], 0], paths[j, pos[1, 1], 0]])\n",
    "            paths[j, pos[1, 1]] = np.array([0, 0])\n",
    "            paths[j, pos[0, 1]] = prov\n",
    "                    \n",
    "            for k in range(i, np.max(paths)+1):\n",
    "                paths = decrement_number_in_array(paths, k)\n",
    "\n",
    "    return points, trim_zeros_3D(paths, axis=1)\n",
    "\n",
    "def simplify_diagram (points, paths):\n",
    "    \"\"\"\n",
    "    Simplify the diagram by removing the points and paths that are not needed, by iterating the function simplify_diagram_it, until the \n",
    "    number of points and paths does not change anymore.\n",
    "    \"\"\"\n",
    "    new_points, new_paths = simplify_diagram_it(points, paths)\n",
    "    new_new_points, new_new_paths = simplify_diagram_it(new_points, new_paths)\n",
    "    while len(new_points) != len(new_new_points) or len(new_paths) != len(new_new_paths):\n",
    "        new_points, new_paths = new_new_points, new_new_paths\n",
    "        new_new_points, new_new_paths = simplify_diagram_it(new_points, new_paths)\n",
    "    return new_new_points, new_new_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9401a6",
   "metadata": {},
   "source": [
    "The product of 2 diagrams is implemented, we can move on to the automatic process, where at a certain order we consider all the possible products of diagrams from lower orders that contribute to processes at that order. \n",
    "\n",
    "But first we still need the counterterms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_counterterm_diagrams (order):\n",
    "    \"\"\"\n",
    "    This function returns all the counterterms at each order until the max order that plans to be calculated, indicated by 'order'.\n",
    "    \"\"\"\n",
    "    #initialize the list of points and paths where the diagrams will be stored, and returned at the end.\n",
    "    all_points = []\n",
    "    all_paths = []\n",
    "    #iterate through the order in perturbation (variable i)\n",
    "    for i in range(2, order + 1):\n",
    "        #initialize the list of points and paths for this order\n",
    "        points_orders = []\n",
    "        paths_orders = []\n",
    "        #at each order, compute the counterterm diagrams\n",
    "        #where j is the number of outgoing particles\n",
    "\n",
    "        if (i > 3):\n",
    "            if (i%2 == 0):\n",
    "                j = i-4\n",
    "                for l in range(len(all_points[j])):\n",
    "                    points_orders.append(all_points[j][l])\n",
    "                for l in range(len(all_paths[j])):\n",
    "                    paths_orders.append(all_paths[j][l])\n",
    "\n",
    "            if (i%2 == 1):\n",
    "                j = i-4\n",
    "                for l in range(len(all_points[j])):\n",
    "                    points_orders.append(all_points[j][l])\n",
    "                for l in range(len(all_paths[j])):\n",
    "                    paths_orders.append(all_paths[j][l])\n",
    "\n",
    "        for j in range(1, i):\n",
    "            \"\"\"\n",
    "            Starting with the points for the diagrams.\n",
    "            \"\"\"\n",
    "            #initialize a dummy array variable for each diagram\n",
    "            points = []\n",
    "            #k is the number of incoming particles\n",
    "            k = i - j\n",
    "            #create the outgoing points for the diagram\n",
    "            for l in range(1, j+1):\n",
    "                points.append([1, l])\n",
    "            #create the point where the counterterm is located\n",
    "            points.append([2, 1])\n",
    "            #create the incoming points for the diagram\n",
    "            for l in range(1, k+1):\n",
    "                points.append([3, l])\n",
    "            #append the points for this diagram\n",
    "            points_orders.append(points)\n",
    "\n",
    "            \"\"\"\n",
    "            Following a similar procedure for the paths.\n",
    "            \"\"\"\n",
    "            #initialize a dummy array variable for each path\n",
    "            paths = []\n",
    "            for l in range(1, j+1):\n",
    "                #create the outgoing paths for the diagram\n",
    "                paths.append([l, j+1])\n",
    "            paths.append([j+1, j+1])\n",
    "            for l in range(1, k+1):\n",
    "                #create the incoming paths for the diagram\n",
    "                paths.append([j+1, j+l+1])\n",
    "            #append the paths for this diagram\n",
    "            paths_orders.append(paths)\n",
    "            \n",
    "        #append the points for this order\n",
    "        all_points.append(points_orders)\n",
    "\n",
    "        #append the paths for this order\n",
    "        all_paths.append(paths_orders)\n",
    "    \n",
    "    return all_points, all_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faf2939",
   "metadata": {},
   "source": [
    "Now we can tackle the diagrams resultant at certain order.\n",
    "\n",
    "From the theory we have:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368cf3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_diagrams_order (points, paths, count, typeofproc, max_order, offset = 0):\n",
    "    curr_order = len(points)\n",
    "    n_types = len(paths[0][0])\n",
    "    max_points = np.zeros((n_types, 2), dtype=int)\n",
    "\n",
    "    n1 = np.zeros(n_types, dtype=int)\n",
    "    n2 = np.zeros(n_types, dtype=int)\n",
    "    for i in range(len(paths[0])): #in number of first order diagrams\n",
    "        for j in range(n_types):\n",
    "            n1[j] = len(np.trim_zeros(in_out_paths(paths[0][i])[j, 0]))\n",
    "            if (n1[j] > max_points[j, 0]):\n",
    "                max_points[j, 0] = n1[j]\n",
    "            n2[j] = len(np.trim_zeros(in_out_paths(paths[0][i])[j, 1]))\n",
    "            if (n2[j] > max_points[j, 1]):\n",
    "                max_points[j, 1] = n2[j]            \n",
    "    for i in range(len(paths[-1])):\n",
    "        for j in range(n_types):\n",
    "            n1[j] = len(np.trim_zeros(in_out_paths(paths[-1][i])[j, 0]))\n",
    "            if (n1[j] > max_points[j, 0]):\n",
    "                max_points[j, 0] = n1[j]\n",
    "            n2[j] = len(np.trim_zeros(in_out_paths(paths[-1][i])[j, 1]))\n",
    "            if (n2[j] > max_points[j, 1]):\n",
    "                max_points[j, 1] = n2[j]\n",
    "\n",
    "    max_connections = np.zeros(n_types, dtype=int)\n",
    "    for i in range(n_types):\n",
    "        max_connections[i] = min(max_points[i, 0], max_points[i, 1])\n",
    "\n",
    "    n_connec = 0\n",
    "    n_connections = np.zeros(n_types, dtype=int)\n",
    "    for i in range(len(paths[0])):\n",
    "        for j in range(n_types):\n",
    "            for k in range(int(max_connections[j])):\n",
    "                n_connections[j] += int(binom(n1[j], i+1)*binom(n2[j], k+1) * factorial(k+1))\n",
    "        #n_connec indicates the total number of connections between the two diagrams\n",
    "        for subset in range(1, 1 << n_types):\n",
    "            product = 1\n",
    "            for i in range(n_types):\n",
    "                if subset & (1 << k):\n",
    "                    product *= n_connections[k]\n",
    "            n_connec += product\n",
    "    n = 0\n",
    "    f = 20\n",
    "\n",
    "    new_points = np.zeros((4*n_types*len(paths[0])*len(paths[-1])*n_connec*(curr_order+1), len(points[0][0]) + len(points[-1][0]), 2))\n",
    "    new_paths = np.zeros((4*n_types*len(paths[0])*len(paths[-1])*n_connec*(curr_order+1), n_types, len(paths[0][0]) + len(paths[-1][0])+np.max(max_connections)+5, 2), dtype=int)\n",
    "    new_count = np.zeros((4*n_types*len(paths[0])*len(paths[-1])*n_connec*(curr_order+1), 1), dtype=int)\n",
    "\n",
    "    counter_points, counter_paths = return_counterterm_diagrams(max_order+1)\n",
    "\n",
    "    for i in range(len(paths[0])):\n",
    "        for j in range(len(paths[-1])):\n",
    "            dummy_points, dummy_paths = connection(trim_zeros_2D(points[-1][j]), trim_zeros_3D(paths[-1][j], axis = 1),trim_zeros_2D(points[0][i]), trim_zeros_3D(paths[0][i], axis=1), offset=offset)\n",
    "            for k in range(len(dummy_paths)):\n",
    "                if(curr_order+1  == max_order): \n",
    "                    in_out_path = in_out_paths(dummy_paths[k])\n",
    "                    if (len(np.trim_zeros(in_out_path[0, 0])) != typeofproc[0][1] or len(np.trim_zeros(in_out_path[0, 1]))!= typeofproc[0][0]):\n",
    "                        continue\n",
    "                simp_points, simp_paths = simplify_diagram(dummy_points, trim_zeros_3D(dummy_paths[k], axis=1))\n",
    "                for l in range(len(simp_points)):\n",
    "                    new_points[n, l] = simp_points[l]\n",
    "                for l in range(n_types):\n",
    "                    for m in range(len(simp_paths[0])):\n",
    "                        new_paths[n, l, m] = simp_paths[l, m]\n",
    "                new_count[n] = count[0][i] * count[-1][j]\n",
    "                n += 1\n",
    "            if (curr_order-1 < len(can_paths)):\n",
    "                dummy_points, dummy_paths = connection(trim_zeros_2D(points[0][i]), trim_zeros_3D(paths[0][i], axis=1),trim_zeros_2D(points[-1][j]), trim_zeros_3D(paths[-1][j], axis = 1), offset=offset)\n",
    "                for k in range(len(dummy_paths)):\n",
    "                    if(curr_order+1  == max_order): \n",
    "                        in_out_path = in_out_paths(dummy_paths[k])\n",
    "                        if (len(np.trim_zeros(in_out_path[0, 0])) != typeofproc[0][1] or len(np.trim_zeros(in_out_path[0, 1]))!= typeofproc[0][0]):\n",
    "                            continue\n",
    "                    simp_points, simp_paths = simplify_diagram(dummy_points, trim_zeros_3D(dummy_paths[k], axis=1))\n",
    "                    for l in range(len(simp_points)):\n",
    "                        new_points[n, l] = simp_points[l]\n",
    "                    for l in range(n_types):\n",
    "                        for m in range(len(simp_paths[0])):\n",
    "                            new_paths[n, l, m] = simp_paths[l, m]\n",
    "                    new_count[n] = count[0][i] * count[-1][j]\n",
    "                    n += 1\n",
    "    for i in range(1, 2):\n",
    "        for j in range(i-1, len(paths)):\n",
    "            if (i+1 + j) == curr_order:\n",
    "                for k in range(len(can_paths[i])):\n",
    "                    for l in range(len(paths[j])):\n",
    "                        dummy_points, dummy_paths = connection(trim_zeros_2D(can_points[i][k]), trim_zeros_3D(can_paths[i][k], axis=1), trim_zeros_2D(points[j][l]), trim_zeros_3D(paths[j][l], axis = 1), offset=offset)\n",
    "                        for m in range(len(dummy_paths)):\n",
    "                            if(curr_order+1  == max_order): \n",
    "                                in_out_path = in_out_paths(dummy_paths[m])\n",
    "                                if (len(np.trim_zeros(in_out_path[0, 0])) != typeofproc[0][0] or len(np.trim_zeros(in_out_path[0, 1]))!= typeofproc[0][1]):\n",
    "                                    continue\n",
    "                            simp_points, simp_paths = simplify_diagram(dummy_points, trim_zeros_3D(dummy_paths[m], axis=1))\n",
    "                            for o in range(len(simp_points)):\n",
    "                                new_points[n, o] = simp_points[o]\n",
    "                            for o in range(n_types):\n",
    "                                for p in range(len(simp_paths[0])):\n",
    "                                    new_paths[n, o, p] = simp_paths[o, p]\n",
    "                            new_count[n] = can_count[i][k] * count[j][l]        \n",
    "                            n += 1\n",
    "                for k in range(len(can_paths[i])):\n",
    "                    for l in range(len(paths[j])):\n",
    "                        dummy_points, dummy_paths = connection(trim_zeros_2D(points[j][l]), trim_zeros_3D(paths[j][l], axis=1), trim_zeros_2D(can_points[i][k]), trim_zeros_3D(can_paths[i][k], axis = 1), offset=offset)\n",
    "                        for m in range(len(dummy_paths)):\n",
    "                            if(curr_order+1  == max_order): \n",
    "                                in_out_path = in_out_paths(dummy_paths[m])\n",
    "                                if (len(np.trim_zeros(in_out_path[0, 0])) != typeofproc[0][0] or len(np.trim_zeros(in_out_path[0, 1]))!= typeofproc[0][1]):\n",
    "                                    continue\n",
    "                            simp_points, simp_paths = simplify_diagram(dummy_points, trim_zeros_3D(dummy_paths[m], axis=1))\n",
    "                            for o in range(len(simp_points)):\n",
    "                                new_points[n, o] = simp_points[o]\n",
    "                            for o in range(n_types):\n",
    "                                for p in range(len(simp_paths[0])):\n",
    "                                    new_paths[n, o, p] = simp_paths[o, p]\n",
    "                            new_count[n] = can_count[i][k] * count[j][l] \n",
    "                            n += 1\n",
    "\n",
    "    for i in range(len(counter_points)):\n",
    "        for j in range(i, len(paths)):\n",
    "            if (i+2+ j +1) == curr_order:\n",
    "                for k in range(len(counter_points[i])):\n",
    "                    for l in range(len(paths[j])):\n",
    "                        dummy_points, dummy_paths = connection(trim_zeros_2D(np.array(counter_points[i][k])), trim_zeros_3D(np.array([counter_paths[i][k],np.zeros_like(counter_paths[i][k])]), axis=1), trim_zeros_2D(points[j][l]), trim_zeros_3D(paths[j][l], axis = 1), offset=offset)\n",
    "                        for m in range(len(dummy_paths)):\n",
    "                            if(curr_order+1  == max_order): \n",
    "                                in_out_path = in_out_paths(dummy_paths[m])\n",
    "                                if (len(np.trim_zeros(in_out_path[0, 0])) != typeofproc[0][0] or len(np.trim_zeros(in_out_path[0, 1]))!= typeofproc[0][1]):\n",
    "                                    continue\n",
    "                            simp_points, simp_paths = simplify_diagram(dummy_points, trim_zeros_3D(dummy_paths[m], axis=1))\n",
    "                            for o in range(len(simp_points)):\n",
    "                                new_points[n, o] = simp_points[o]\n",
    "                            for o in range(n_types):\n",
    "                                for p in range(len(simp_paths[0])):\n",
    "                                    new_paths[n, o, p] = simp_paths[o, p]\n",
    "                            new_count[n] = can_count[i][k] * count[j][l]        \n",
    "                            n += 1\n",
    "                for k in range(len(counter_points[i])):\n",
    "                    for l in range(len(paths[j])):\n",
    "                        dummy_points, dummy_paths = connection(trim_zeros_2D(points[j][l]), trim_zeros_3D(paths[j][l], axis=1), trim_zeros_2D(np.array(counter_points[i][k])), trim_zeros_3D(np.array([counter_paths[i][k],np.zeros_like(counter_paths[i][k])]), axis=1), offset=offset)\n",
    "                        for m in range(len(dummy_paths)):\n",
    "                            if(curr_order+1  == max_order): \n",
    "                                in_out_path = in_out_paths(dummy_paths[m])\n",
    "                                if (len(np.trim_zeros(in_out_path[0, 0])) != typeofproc[0][0] or len(np.trim_zeros(in_out_path[0, 1]))!= typeofproc[0][1]):\n",
    "                                    continue\n",
    "                            simp_points, simp_paths = simplify_diagram(dummy_points, trim_zeros_3D(dummy_paths[m], axis=1))\n",
    "                            for o in range(len(simp_points)):\n",
    "                                new_points[n, o] = simp_points[o]\n",
    "                            for o in range(n_types):\n",
    "                                for p in range(len(simp_paths[0])):\n",
    "                                    new_paths[n, o, p] = simp_paths[o, p]\n",
    "                            new_count[n] = can_count[i][k] * count[j][l] \n",
    "                            n += 1 \n",
    "\n",
    "                \n",
    "    #In the case of the gluon diagrams, there is only it second order diagrams, so this will only be used for curr_order = 1, but it should be general, for the cases where \n",
    "    #there are higher order canonical diagrams.\n",
    "    if curr_order < len(can_paths):\n",
    "        for i in range(len(can_points[curr_order])):\n",
    "            for j in range(len(can_points[curr_order][i])):\n",
    "                new_points[n, j] = can_points[curr_order][i][j]\n",
    "            for j in range(n_types):\n",
    "                for k in range(len(can_paths[curr_order][i][j])):\n",
    "                    new_paths[n, j, k] = can_paths[curr_order][i][j][k]\n",
    "            new_count[n] = can_count[curr_order][i][0]\n",
    "            n += 1\n",
    "    \n",
    "    if curr_order < len(counter_points):\n",
    "        for i in range(len(counter_points[curr_order-1])):\n",
    "            for j in range(len(counter_points[curr_order-1][i])):\n",
    "                new_points[n, j] = counter_points[curr_order-1][i][j]\n",
    "            for j in range(n_types):\n",
    "                for k in range(len(counter_paths[curr_order-1][i])):\n",
    "                    if j == 0:\n",
    "                        new_paths[n, j, k] = counter_paths[curr_order-1][i][k]\n",
    "                    else:\n",
    "                        new_paths[n, j, k] = np.zeros(2, dtype=int)\n",
    "            new_count[n] = 0\n",
    "            n += 1\n",
    "    \n",
    "    return new_points, new_paths, new_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64291ff1",
   "metadata": {},
   "source": [
    "After the previous functions many similar diagrams are produced, for readability we are interested in grouping the similar diagrams into a single one and just add to a counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de678735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Chatgpt\n",
    "def diagram_signature(paths: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    paths: (K, M, 2)\n",
    "    returns: a tuple of length K, where each element is\n",
    "             a flattened tuple of that row's points sorted lexicographically.\n",
    "    \"\"\"\n",
    "    sig = []\n",
    "    for row in paths:\n",
    "        # sort points by (x, then y)\n",
    "        idx = np.lexsort((row[:,1], row[:,0]))\n",
    "        sorted_row = row[idx]\n",
    "        sig.append(tuple(sorted_row.ravel()))\n",
    "    return tuple(sig)\n",
    "\n",
    "#From Chatgpt\n",
    "def group_diagrams(points: np.ndarray,\n",
    "                   paths: np.ndarray,\n",
    "                   numbers: np.ndarray):\n",
    "    \"\"\"\n",
    "    points:  (N, P, 2)\n",
    "    paths:   (N, K, M, 2)\n",
    "    numbers: (N, 1)\n",
    "    \"\"\"\n",
    "    # 1) filter out the “all-zero” diagrams in one vectorized mask\n",
    "    nonzero_mask = ~((paths == 0).all(axis=(1,2,3)))\n",
    "    pts  = points [nonzero_mask]\n",
    "    pths = paths  [nonzero_mask]\n",
    "    nums = numbers[nonzero_mask, 0]\n",
    "\n",
    "    # 2) single-pass grouping via a dict\n",
    "    sig2group = {}\n",
    "    grouped_pts  = []\n",
    "    grouped_pths = []\n",
    "    counts       = []\n",
    "\n",
    "    for idx, (pt, pth, num) in enumerate(zip(pts, pths, nums)):\n",
    "        sig = diagram_signature(pth)\n",
    "        if sig in sig2group:\n",
    "            gi = sig2group[sig]\n",
    "            counts[gi] += num\n",
    "        else:\n",
    "            gi = len(grouped_pts)\n",
    "            sig2group[sig] = gi\n",
    "            grouped_pts .append(pt)\n",
    "            grouped_pths.append(pth)\n",
    "            counts    .append(num)\n",
    "\n",
    "    # 3) stack into arrays\n",
    "    G = len(grouped_pts)\n",
    "    grouped_points = np.stack(grouped_pts, axis=0)   # (G, P, 2)\n",
    "    grouped_paths  = np.stack(grouped_pths, axis=0)  # (G, K, M, 2)\n",
    "    counts         = np.array(counts)                # (G,)\n",
    "\n",
    "    return grouped_points, grouped_paths, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902c96c4",
   "metadata": {},
   "source": [
    "One last challenge involve the form of the diagrams after all these operations, they tend to have superposition between the different lines, making the interpretation of the diagrams hard or even impossible. Thus, we need to implement a way to detect when these problems arise and solve them.\n",
    "\n",
    "But this is no trivial task, the following implementation can and should be revised for a better solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Chatgpt\n",
    "def find_shortest_undirected_path(paths: np.ndarray, start: int, end: int):\n",
    "    \"\"\"\n",
    "    Given:\n",
    "      - paths: array of shape (T, P, 2), listing edges [u, v]\n",
    "      - start: starting node\n",
    "      - end:   target node\n",
    "    Returns:\n",
    "      - (num_hops, path_nodes)\n",
    "        * num_hops: minimum number of edges\n",
    "        * path_nodes: list of nodes [start, ..., end]\n",
    "    Raises:\n",
    "      ValueError if no route exists.\n",
    "    \"\"\"\n",
    "    # 1) Build adjacency lists, preserving your input order\n",
    "    adj = {}  # node -> list of neighbors in the order encountered\n",
    "    T, P, _ = paths.shape\n",
    "    for t in range(T):\n",
    "        for p in range(P):\n",
    "            u, v = int(paths[t, p, 0]), int(paths[t, p, 1])\n",
    "            # skip placeholders or self‐loops\n",
    "            if u == v or (u == 0 and v == 0):\n",
    "                continue\n",
    "            adj.setdefault(u, []).append(v)\n",
    "            adj.setdefault(v, []).append(u)\n",
    "\n",
    "    # 2) BFS to find shortest path\n",
    "    visited = {start}\n",
    "    queue = deque([(start, [start])])  # (current_node, path_so_far)\n",
    "    while queue:\n",
    "        node, path = queue.popleft()\n",
    "        # explore neighbors in **exact** order they were added\n",
    "        for nbr in adj.get(node, []):\n",
    "            if nbr in visited:\n",
    "                continue\n",
    "            new_path = path + [nbr]\n",
    "            if nbr == end:\n",
    "                return len(new_path) - 1, new_path\n",
    "            visited.add(nbr)\n",
    "            queue.append((nbr, new_path))\n",
    "\n",
    "    raise ValueError(f\"No path found from {start} to {end}\")\n",
    "\n",
    "#From Chatgpt\n",
    "def is_ordered_route(route):\n",
    "    \"\"\"\n",
    "    Return True if `route` is strictly monotonic (either all increasing or all decreasing).\n",
    "    Examples:\n",
    "      [1, 3, 4, 5] → True (increasing)\n",
    "      [6, 5, 3, 2] → True (decreasing)\n",
    "      [1, 2, 2, 3] → False (not strict)\n",
    "      [1, 3, 2]    → False (changes direction)\n",
    "    \"\"\"\n",
    "    if len(route) < 2:\n",
    "        return True\n",
    "    # check strictly increasing\n",
    "    inc = all(route[i] < route[i+1] for i in range(len(route)-1))\n",
    "    # check strictly decreasing\n",
    "    dec = all(route[i] > route[i+1] for i in range(len(route)-1))\n",
    "    return inc or dec\n",
    "\n",
    "#From Chatgpt\n",
    "def find_same_height_outside(points: np.ndarray, route_ids: list[int]) -> list[int]:\n",
    "    \"\"\"\n",
    "    Given:\n",
    "      - points:  (N,2) array of (x,y) coords, zero-based indexing\n",
    "      - route_ids: list of 1-based point IDs (from your path), all sharing the same y\n",
    "    Returns:\n",
    "      - list of 1-based IDs of all other points whose y == that common y\n",
    "    \"\"\"\n",
    "    # convert to zero-based indices\n",
    "    idxs = [rid - 1 for rid in route_ids]\n",
    "    y_route = points[idxs, 1]\n",
    "    if not np.allclose(y_route, y_route[0]):\n",
    "        raise ValueError(f\"Route points do not share one y: {y_route}\")\n",
    "    y0 = y_route[0]\n",
    "\n",
    "    # mask all points at that y, then exclude route indices\n",
    "    same_y = np.isclose(points[:, 1], y0)\n",
    "    mask = same_y.copy()\n",
    "    mask[idxs] = False\n",
    "\n",
    "    outside_idxs = np.nonzero(mask)[0]\n",
    "    # convert back to 1-based IDs\n",
    "    return (outside_idxs + 1).tolist()\n",
    "\n",
    "#From Chatgpt\n",
    "def equalize_x_spacing(points: np.ndarray, spacing: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return a new (N×2) array where the x-coords have been remapped so that\n",
    "      - each unique original x is assigned to 0, spacing, 2*spacing, … in ascending order,\n",
    "      - any two points that had the same x stay tied,\n",
    "      - the y-coords are left unchanged.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    points : np.ndarray of shape (N,2)\n",
    "        Your original (x,y) coordinates.\n",
    "    spacing : float, default=1.0\n",
    "        The distance between consecutive unique x-positions.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_pts : np.ndarray of shape (N,2)\n",
    "        The transformed points.\n",
    "    \"\"\"\n",
    "    # 1) find the sorted unique x-values\n",
    "    orig_x = points[:,0]\n",
    "    uniq = np.unique(orig_x)\n",
    "    \n",
    "    # 2) build a map: original x → new x\n",
    "    #    e.g. uniq = [1.2, 3.4, 7.9]  →  {1.2:0, 3.4:1*spacing, 7.9:2*spacing}\n",
    "    mapping = {x: i * spacing for i, x in enumerate(uniq)}\n",
    "    \n",
    "    # 3) apply it\n",
    "    new_x = np.vectorize(mapping.get)(orig_x)\n",
    "    new_pts = points.copy()\n",
    "    new_pts[:,0] = new_x\n",
    "    return new_pts\n",
    "\n",
    "def reposition_diagram (points, in_out_path, paths, typeofproc, print_=False, spacing_=1.0):\n",
    "    minx_point = np.min(points[:, 0])\n",
    "    maxx_point = np.max(points[:, 0])\n",
    "\n",
    "    for i in range(len(in_out_path)):\n",
    "        for j in range(len(in_out_path[i, 0])):\n",
    "            if in_out_path[i, 0][j] == 0:\n",
    "                continue\n",
    "            if points[in_out_path[i, 0][j]-1, 0] == maxx_point:\n",
    "                continue\n",
    "            else:\n",
    "                points[in_out_path[i, 0][j]-1, 1] = maxx_point - points[in_out_path[i, 0][j]-1, 0]\n",
    "                points[in_out_path[i, 0][j]-1, 0] = maxx_point\n",
    "        for j in range(len(in_out_path[i, 1])):\n",
    "            if in_out_path[i, 1][j] == 0:\n",
    "                continue\n",
    "            if points[in_out_path[i, 1][j]-1, 0] == minx_point:\n",
    "                continue\n",
    "            else:\n",
    "                points[in_out_path[i, 1][j]-1, 1] = - minx_point + points[in_out_path[i, 1][j]-1, 0]\n",
    "                points[in_out_path[i, 1][j]-1, 0] = minx_point\n",
    "\n",
    "    if typeofproc == [2, 2]:\n",
    "        maxy_point = 5\n",
    "        path1 = find_shortest_undirected_path(paths, in_out_path[0, 0][0], in_out_path[0, 1][0])\n",
    "        path2 = find_shortest_undirected_path(paths, in_out_path[0, 0][1], in_out_path[0, 1][1])\n",
    "        path3 = find_shortest_undirected_path(paths, in_out_path[0, 0][0], in_out_path[0, 1][1])\n",
    "        path4 = find_shortest_undirected_path(paths, in_out_path[0, 0][1], in_out_path[0, 1][0])\n",
    "        if path1[0] < path3[0]:\n",
    "            if(print_):\n",
    "                print(path2[1])\n",
    "            for i in path1[1]:\n",
    "                points[i-1, 1] = maxy_point\n",
    "            if is_ordered_route(path1[1]) == False:\n",
    "                for i in range(1, len(path1[1])-1):\n",
    "                    points[path1[1][i]-1, 1] = (maxy_point-1)/2\n",
    "            for i in path2[1]:\n",
    "                points[i-1, 1] = 1\n",
    "            for i in find_same_height_outside (points, path2[1]):\n",
    "                points[i-1, 1] = (maxy_point-1)/2\n",
    "        \n",
    "        else:\n",
    "            if(print_):\n",
    "                print(path4[1])\n",
    "            for i in path3[1]:\n",
    "                points[i-1, 1] = maxy_point\n",
    "            if is_ordered_route(path3[1]) == False:\n",
    "                for i in range(1, len(path3[1])-1):\n",
    "                    points[path3[1][i]-1, 1] = (maxy_point-1)/2\n",
    "            for i in path4[1]:\n",
    "                points[i-1, 1] = 1\n",
    "            for i in find_same_height_outside (points, path4[1]):\n",
    "                points[i-1, 1] = (maxy_point-1)/2\n",
    "    elif typeofproc == [2, 1]:\n",
    "        maxy_point = 5\n",
    "        path1 = find_shortest_undirected_path(paths, in_out_path[0, 0][0], in_out_path[0, 1][0])\n",
    "        path2 = find_shortest_undirected_path(paths, in_out_path[0, 0][0], in_out_path[0, 1][1])\n",
    "        if path1[0] < path2[0]:\n",
    "            for i in path1[1]:\n",
    "                points[i-1, 1] = maxy_point\n",
    "            if is_ordered_route(path1[1]) == False:\n",
    "                for i in range(1, len(path1[1])-1):\n",
    "                    points[path1[1][i]-1, 1] = (maxy_point-1)/2\n",
    "            for i in path2[1]:\n",
    "                points[i-1, 1] = 1\n",
    "            for i in find_same_height_outside (points, path2[1]):\n",
    "                points[i-1, 1] = (maxy_point-1)/2\n",
    "        else:\n",
    "            for i in path2[1]:\n",
    "                points[i-1, 1] = maxy_point\n",
    "            if is_ordered_route(path2[1]) == False:\n",
    "                for i in range(1, len(path2[1])-1):\n",
    "                    points[path2[1][i]-1, 1] = (maxy_point-1)/2\n",
    "            for i in path1[1]:\n",
    "                points[i-1, 1] = 1\n",
    "            for i in find_same_height_outside (points, path1[1]):\n",
    "                points[i-1, 1] = (maxy_point-1)/2\n",
    "    elif typeofproc == [1, 2]:\n",
    "        maxy_point = 3\n",
    "        path1 = find_shortest_undirected_path(paths, in_out_path[0, 0][0], in_out_path[0, 1][0])\n",
    "        path2 = find_shortest_undirected_path(paths, in_out_path[0, 0][1], in_out_path[0, 1][0])\n",
    "        if path1[0] < path2[0]:\n",
    "            for i in path1[1]:\n",
    "                points[i-1, 1] = maxy_point\n",
    "            if is_ordered_route(path1[1]) == False:\n",
    "                for i in range(1, len(path1[1])-1):\n",
    "                    points[path1[1][i]-1, 1] = (maxy_point-1)/2\n",
    "            for i in path2[1]:\n",
    "                points[i-1, 1] = 1\n",
    "            for i in find_same_height_outside (points, path2[1]):\n",
    "                points[i-1, 1] = (maxy_point-1)/2\n",
    "        else:\n",
    "            for i in path2[1]:\n",
    "                points[i-1, 1] = maxy_point\n",
    "            if is_ordered_route(path2[1]) == False:\n",
    "                for i in range(1, len(path2[1])-1):\n",
    "                    points[path2[1][i]-1, 1] = (maxy_point-1)/2\n",
    "            for i in path1[1]:\n",
    "                points[i-1, 1] = 1\n",
    "            for i in find_same_height_outside (points, path1[1]):\n",
    "                points[i-1, 1] = (maxy_point-1)/2\n",
    "    elif typeofproc == [1, 1]:\n",
    "        maxy_point = 3\n",
    "        path1 = find_shortest_undirected_path(paths, in_out_path[0, 0][0], in_out_path[0, 1][0])\n",
    "        if path1[0] < 2:\n",
    "            for i in path1[1]:\n",
    "                points[i-1, 1] = maxy_point\n",
    "            if is_ordered_route(path1[1]) == False:\n",
    "                for i in range(1, len(path1[1])-1):\n",
    "                    points[path1[1][i]-1, 1] = maxy_point\n",
    "        else:\n",
    "            for i in path1[1]:\n",
    "                points[i-1, 1] = 1\n",
    "            for i in find_same_height_outside (points, path1[1]):\n",
    "                points[i-1, 1] = maxy_point\n",
    "        \n",
    "    points = equalize_x_spacing(points, spacing=spacing_)\n",
    "\n",
    "    return points\n",
    "\n",
    "def detect_3p_loops(points, paths):\n",
    "    loop = np.zeros((len(paths), int(len(trim_zeros_2D(paths[0]))/3), 3), dtype=int)\n",
    "    n = 0\n",
    "    for i in range(len(paths)):\n",
    "        if np.count_nonzero(paths[i]) == 0:\n",
    "            continue\n",
    "        path = trim_zeros_2D(paths[i])\n",
    "        if (len(path) < 3):\n",
    "            continue\n",
    "        index = np.arange(len(path))\n",
    "        j = 0\n",
    "        for j in range(len(path)):\n",
    "            if j in index:\n",
    "                start = path[j, 0]\n",
    "                end = path[j, 1]\n",
    "                next = -1\n",
    "                for k in range(len(path)):\n",
    "                    if(k != j and k in index):\n",
    "                        if path[k, 0] == start:\n",
    "                            next = path[k, 1]\n",
    "                        elif path[k, 1] == start:\n",
    "                            next = path[k, 0]\n",
    "                        if next == -1:\n",
    "                            continue\n",
    "                        for l in range(len(path)):\n",
    "                            next2 = -1\n",
    "                            if (l != j and l!= k and l in index):\n",
    "                                if path[l, 0] == next:\n",
    "                                    next2 = path[l, 1]\n",
    "                                elif path[l, 1] == next:\n",
    "                                    next2 = path[l, 0]\n",
    "                                if next2 == next:\n",
    "                                    continue\n",
    "                                if next2 == end:\n",
    "                                    loop[i, n, 0] = j+1\n",
    "                                    loop[i, n, 1] = k+1\n",
    "                                    loop[i, n, 2] = l+1\n",
    "                                    index = np.delete(index, np.where(index == j))\n",
    "                                    index = np.delete(index, np.where(index == k))\n",
    "                                    index = np.delete(index, np.where(index == l))\n",
    "\n",
    "    return trim_zeros_3D(loop, axis=0)\n",
    "\n",
    "def detect_superposition(points, paths):\n",
    "    loop = detect_3p_loops(points, paths)\n",
    "    if np.count_nonzero(loop) == 0:\n",
    "        return points, paths  \n",
    "    else:\n",
    "        for i in range(len(loop)):\n",
    "            if np.count_nonzero(loop[i]) == 0:\n",
    "                continue\n",
    "            for j in range(len(loop[i])):\n",
    "                if np.count_nonzero(loop[i, j]) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    height = points[paths[i,loop[i, j, 0]-1, 0]-1, 1]\n",
    "                    sorted_array = sorted([paths[i,loop[i, j, 0]-1, 0], paths[i,loop[i, j, 1]-1, 0], paths[i,loop[i, j, 2]-1, 0], paths[i,loop[i, j, 0]-1, 1], paths[i,loop[i, j, 1]-1, 1], paths[i,loop[i, j, 2]-1, 1]])\n",
    "                    same_height = True\n",
    "                    for k in sorted_array:\n",
    "                        if points[k-1, 1] != height:\n",
    "                            same_height = False\n",
    "                            break\n",
    "                    if same_height:\n",
    "                        middle = sorted_array[2]-1\n",
    "                        points[middle, 1] = height+1\n",
    "                    else:\n",
    "                        continue\n",
    "        return points, paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe3ac71",
   "metadata": {},
   "source": [
    "Finally, the results are presented to the user, through the notebook for saved in folder.\n",
    "\n",
    "And the function to calculate the following order, from a recollection of functions previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ba7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent_order(points, paths, count_, typeofproc, index_ = True,  lines_ = [\"solid\", \"dotted\"], colors_ = [\"black\", \"black\"], directory_ = \"\", docount = True, spacing = 1.0):\n",
    "    n=1\n",
    "    for i in range(len(points)):\n",
    "        in_out_paths_ = in_out_paths(paths[i])\n",
    "        inp = 0\n",
    "        out = 0\n",
    "        for j in range(len(paths[0])):\n",
    "            inp += len(np.trim_zeros(in_out_paths_[j, 0]))\n",
    "            out += len(np.trim_zeros(in_out_paths_[j, 1]))\n",
    "        if typeofproc == []:\n",
    "            points[i], paths[i] = detect_superposition(points[i], paths[i])\n",
    "            points[i] = reposition_diagram(points[i], in_out_paths_, paths[i], [inp, out], spacing_=spacing)\n",
    "            if docount:    \n",
    "                if directory_ != \"\":\n",
    "                    represent_diagram(points[i], paths[i], index=index_, line=lines_, colors=colors_, count=count_[i], directory=directory_+str(n))\n",
    "                else:\n",
    "                    represent_diagram(points[i], paths[i], index=index_, line=lines_, colors=colors_, count=count_[i])\n",
    "            else:\n",
    "                if directory_ != \"\":\n",
    "                    represent_diagram(points[i], paths[i], index=index_, line=lines_, colors=colors_, count=0, directory=directory_+str(n))\n",
    "                else:\n",
    "                    represent_diagram(points[i], paths[i], index=index_, line=lines_, colors=colors_, count=0)\n",
    "            n += 1\n",
    "        elif inp == typeofproc[0][1] and out == typeofproc[0][0]:\n",
    "            points[i], paths[i] = detect_superposition(points[i], paths[i])\n",
    "            points[i] = reposition_diagram(points[i], in_out_paths_, paths[i], typeofproc[0], spacing_=spacing)\n",
    "            if docount:\n",
    "                if directory_ != \"\":\n",
    "                    represent_diagram(points[i], paths[i], index=index_, line=lines_, colors=colors_, count=count_[i], directory=directory_+str(n))\n",
    "                else:\n",
    "                    represent_diagram(points[i], paths[i], index=index_, line=lines_, colors=colors_, count=count_[i])\n",
    "            else:\n",
    "                if directory_ != \"\":\n",
    "                    represent_diagram(points[i], paths[i], index=index_, line=lines_, colors=colors_, count=0, directory=directory_+str(n))\n",
    "                else:\n",
    "                    represent_diagram(points[i], paths[i], index=index_, line=lines_, colors=colors_, count=0)\n",
    "            n += 1\n",
    "\n",
    "\n",
    "def next_order (points, paths, count, typeofproc, max_order, print_reduction = False):\n",
    "    next_points, next_paths, next_count = combine_diagrams_order(points, paths, count, typeofproc, max_order, offset = 0)\n",
    "    if print_reduction:\n",
    "        print(\"Number of diagrams in order\", print(len(points)), \":\", len(next_points))\n",
    "    return group_diagrams(next_points, next_paths, next_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
